---
titre: Test de montÃ©e en charge - Locust & Artillery
type: module
jour: 21
ordre: 1
tags: cd, test, locust, artillery, python, devops
---

# ðŸš€ Cours : Tests de montÃ©e en charge & Framework Locust

> **Objectif du cours** : Comprendre les tests de montÃ©e en charge, savoir les appliquer dans un contexte professionnel ou personnel, et apprendre Ã  utiliser **Locust** (framework Python) pour simuler des utilisateurs et mesurer la rÃ©sistance dâ€™une application.

---

## 1ï¸âƒ£ Introduction : Pourquoi faire des tests de montÃ©e en charge ?

Lorsquâ€™une application est mise en ligne, il est essentiel de **vÃ©rifier sa capacitÃ© Ã  supporter un grand nombre dâ€™utilisateurs simultanÃ©s**.

Les tests de montÃ©e en charge (Load Testing) permettent de :
- Identifier le **seuil critique** de lâ€™application (au-delÃ  duquel elle ralentit ou plante),
- DÃ©tecter les **goulets dâ€™Ã©tranglement** (CPU, RAM, base de donnÃ©es),
- Ã‰valuer la **stabilitÃ©** et la **scalabilitÃ©** du systÃ¨me,
- PrÃ©venir les **pannes** en production.

### ðŸŽ¯ Exemple dâ€™entreprises
- **E-commerce** : gÃ©rer un pic de trafic pendant le Black Friday.  
- **Service SaaS** : supporter 10 000 connexions simultanÃ©es sans crash.  
- **Autoentrepreneur** : vÃ©rifier que son site portfolio reste fluide mÃªme si 100 visiteurs arrivent en mÃªme temps aprÃ¨s une campagne.

---

## 2ï¸âƒ£ Concepts fondamentaux

### ðŸ§± Seuil critique
Une application peut fonctionner correctement avec 100 utilisateurs mais **saturer Ã  1 000**.  
Au-delÃ  du seuil critique, les temps de rÃ©ponse explosent, voire le serveur tombe.

### âš”ï¸ Risques & SÃ©curitÃ©
Une **attaque de dÃ©ni de service (DoS)** exploite ces faiblesses : surcharge du CPU ou de la mÃ©moire, saturation des connexions, etc.

### âš™ï¸ Ressources Ã  surveiller
| Ressource | RÃ´le | SymptÃ´me de surcharge |
|------------|------|------------------------|
| **CPU** | Calculs, traitements logiques | Latence, freeze, erreurs 500 |
| **RAM** | Stockage temporaire des donnÃ©es | Crash, swap disque, lenteur |
| **Disque** | AccÃ¨s aux fichiers/logs | Blocages, IOwait Ã©levÃ©s |
| **RÃ©seau** | Transmission des donnÃ©es | Timeout, goulot dâ€™Ã©tranglement |

### ðŸ’¡ Solutions possibles
- **Optimiser le code** (algorithmes, requÃªtes SQL, cache),
- **Scaling horizontal** (ajouter des instances serveur),
- **Scaling vertical** (augmenter CPU/RAM),
- **SystÃ¨mes de queue** (RabbitMQ, Celery),
- **RÃ©plication** (serveurs ou bases de donnÃ©es).

---

## 3ï¸âƒ£ Simulation dâ€™utilisateurs

Les tests de charge consistent Ã  **simuler des utilisateurs rÃ©els** interagissant avec ton application :
- Navigation sur plusieurs pages,
- Connexion / dÃ©connexion,
- Achats, formulaires, API RESTâ€¦

Ces scÃ©narios permettent de mesurer les performances **dans un contexte rÃ©aliste**.

---

## 4ï¸âƒ£ ðŸ Framework Python : Locust

### Introduction

**Locust** est un framework open-source de tests de charge Ã©crit en Python.  
Il permet de simuler des milliers dâ€™utilisateurs virtuels exÃ©cutant des scÃ©narios dÃ©finis dans un fichier Python (`locustfile.py`).

#### ðŸ”§ CaractÃ©ristiques
- Ã‰crit en **Python** (simple et flexible),
- Interface web intÃ©grÃ©e (`localhost:8089`),
- Compatible avec **GitLab CI/CD**,
- Exporte des rapports en **CSV/HTML**.

---

### Installation et prÃ©requis

#### VÃ©rification Python
```bash
python3 --version
```
> Locust nÃ©cessite Python **â‰¥ 3.7**

#### Installation
```bash
pip install locust
```

---

### CrÃ©ation dâ€™un premier test : `locustfile.py`

Ce fichier contient les scÃ©narios utilisateurs Ã  exÃ©cuter.

```python
from locust import HttpUser, task, between

class FirstLoadTest(HttpUser):
    wait_time = between(1, 3)  # DÃ©lai entre deux requÃªtes

    @task
    def home_page(self):
        self.client.get("/")

    @task
    def about_page(self):
        self.client.get("/about")
```

#### ðŸ” Explication
- `HttpUser` â†’ reprÃ©sente un utilisateur virtuel.  
- `@task` â†’ dÃ©finit une action Ã  rÃ©pÃ©ter pendant le test.  
- `self.client.get()` â†’ effectue une requÃªte HTTP.  
- `wait_time` â†’ simule un dÃ©lai entre deux requÃªtes pour reproduire un comportement humain.

---

### Lancer Locust

#### Commande
```bash
locust
```
âž¡ï¸ Par dÃ©faut, Locust dÃ©marre une interface web sur [http://localhost:8089](http://localhost:8089)

#### Dans lâ€™interface :
- **Host** : URL de ton application (ex. `http://127.0.0.1:5000` ou ton site),
- **Users** : nombre dâ€™utilisateurs simultanÃ©s,
- **Spawn rate** : nouveaux utilisateurs/seconde,
- **Run time** : durÃ©e du test.

Locust va alors simuler la charge et afficher les rÃ©sultats en temps rÃ©el.

---

### Analyse des rÃ©sultats

#### Indicateurs importants
| Indicateur | Description |
|-------------|-------------|
| **RPS (Requests per Second)** | Nombre de requÃªtes traitÃ©es par seconde |
| **Response Time (ms)** | Temps moyen de rÃ©ponse |
| **Fail %** | Taux dâ€™erreur des requÃªtes |
| **Users** | Nombre dâ€™utilisateurs actifs |
| **Throughput** | Volume total de donnÃ©es Ã©changÃ©es |

#### Export des rÃ©sultats
Locust peut exporter les rÃ©sultats :
```bash
locust -f locustfile.py --headless -u 100 -r 10 -t 5m --host=http://localhost:8000 --csv=results
```

---

### IntÃ©gration avec GitLab CI/CD

#### Exemple de pipeline GitLab
```yaml
# .gitlab-ci.yml â€” Test de charge automatisÃ©
stages: [test]

load_test:
  image: python:3.10
  stage: test
  script:
    - pip install locust
    - locust -f locustfile.py --headless -u 50 -r 5 -t 2m --host=http://app:5000 --csv=results
  artifacts:
    paths:
      - results_stats.csv
      - results_failures.csv
  only:
    - main
```

#### ParamÃ¨tres utiles
- `-u` : nombre dâ€™utilisateurs simultanÃ©s,
- `-r` : utilisateurs ajoutÃ©s par seconde,
- `-t` : durÃ©e totale du test,
- `--csv` : export des rÃ©sultats.

#### ðŸ”„ IntÃ©gration continue
Les tests de charge peuvent Ãªtre **dÃ©clenchÃ©s automatiquement** Ã  chaque `merge request`.  
En cas dâ€™Ã©chec, **la fusion est bloquÃ©e** et les rÃ©sultats apparaissent dans GitLab CI/CD.

---

### ðŸ”¬ Exemple dâ€™analyse de rÃ©sultats

| ScÃ©nario | Utilisateurs | Erreurs | Temps moyen | Observation |
|-----------|---------------|----------|--------------|--------------|
| Home Page | 100 | 0% | 150 ms | Stable |
| Login API | 100 | 12% | 1200 ms | RequÃªtes lentes, Ã  optimiser |
| Checkout | 200 | 40% | 2400 ms | Saturation de la base de donnÃ©es |

---

### ðŸ”§ Optimiser aprÃ¨s les tests

1. **Optimiser le code** (requÃªtes SQL, cache, asynchronisme).
2. **Surveiller lâ€™infrastructure** (CPU/RAM, scaling horizontal).
3. **Utiliser du caching** (Redis, CDN).
4. **Mettre en file dâ€™attente** les tÃ¢ches lourdes (RabbitMQ, Celery).
5. **Mettre en place du monitoring** (Prometheus, Grafana, Datadog).

---

### ðŸ’¡ Bonnes pratiques

- Toujours tester **dans un environnement isolÃ©** (prÃ©-prod ou staging).  
- Ne jamais lancer un test massif **sur la prod** sans validation.  
- Analyser les logs systÃ¨me et applicatifs pendant les tests.  
- Automatiser les tests de charge dans le pipeline CI/CD.  
- Garder des **rapports historiques** pour comparer les versions.

---

### ðŸ§  Ã€ retenir

> Les tests de montÃ©e en charge permettent dâ€™anticiper les problÃ¨mes de performance **avant** quâ€™ils nâ€™impactent les utilisateurs rÃ©els.  
> Locust offre un moyen simple, rapide et Pythonique dâ€™automatiser ces tests et de les intÃ©grer Ã  un cycle DevOps complet.

---

### ðŸ“Ž Commandes rÃ©capitulatives

#### Interface Web (par dÃ©faut)

```bash
locust -f locustfile.py --host http://127.0.0.1:8000

```

- Ouvre lâ€™UI sur **http://localhost:8089**
- Tu saisis **Users**, **Spawn rate** et tu lances depuis le navigateur

#### Mode headless (sans UI) + rÃ©sumÃ© final uniquement

```bash
locust -f locustfile.py --headless --only-summary \
  -u 100 -r 10 -t 2m --host http://127.0.0.1:8000

```

---

### ðŸ§© Options essentielles

#### Cible & scÃ©nario

- `f, --locustfile PATH` : fichier test (par dÃ©faut `locustfile.py`)
- `-host URL` : URL cible (peut aussi Ãªtre dÃ©finie dans le code)

#### Charge & durÃ©e

- `u, --users N` : nombre dâ€™utilisateurs simulÃ©s
- `r, --spawn-rate N` : nouveaux utilisateurs par seconde
- `t, --run-time D` : durÃ©e totale (ex : `30s`, `2m`, `1h`)
- `-stop-timeout S` : arrÃªt **gracieux** des users (sec) Ã  la fin

#### Sortie & rapports

- `-headless` : exÃ©cution sans interface web
- `-only-summary` : **nâ€™affiche que le rÃ©sumÃ© final**
- `-csv PREFIX` : export CSV (`PREFIX_stats.csv`, `PREFIX_failures.csv`, â€¦)
- `-csv-full-history` : CSV avec chronologie complÃ¨te (timeseries)
- `-html REPORT.html` : gÃ©nÃ¨re un **rapport HTML** Ã  la fin

#### Logs

- `-loglevel LEVEL` : `INFO`, `DEBUG`, `WARNING`, â€¦
- `-logfile FILE` : envoie les logs dans un fichier

#### UI Web (quand tu veux la garder mais lâ€™exposer ailleurs)

- `-web-host 0.0.0.0` : Ã©coute sur toutes les interfaces
- `-web-port 8089` : port de lâ€™UI

---

### ðŸŽ›ï¸ Filtrer/organiser les tÃ¢ches

> Marque tes tÃ¢ches avec @tag("login"), @tag("checkout") dans le code.
> 
- `-tags login,checkout` : **inclure** seulement ces tags
- `-exclude-tags slow,admin` : **exclure** ces tags

---

### ðŸ§ª ScÃ©narios concrets (recettes)

#### 1) Petit test de fumÃ©e (CI rapide)

```bash
locust -f locustfile.py --headless --only-summary \
  -u 20 -r 5 -t 1m --host http://127.0.0.1:8000

```

#### 2) Campagne avec rapport HTML + CSV complet

```bash
locust -f locustfile.py --headless \
  -u 200 -r 20 -t 10m --host https://app.example.com \
  --csv results/run_$(date +%F_%H%M) --csv-full-history \
  --html report_$(date +%F_%H%M).html

```

#### 3) Test sur un sous-ensemble de tÃ¢ches (tags)

```bash
locust -f locustfile.py --headless --only-summary \
  -u 100 -r 10 -t 5m --host https://api.example.com \
  --tags login,search

```

#### 4) UI exposÃ©e Ã  distance (docker/vm)

```bash
locust -f locustfile.py --host http://service:8000 \
  --web-host 0.0.0.0 --web-port 8089

```

---

### ðŸ§® ExÃ©cution distribuÃ©e (maÃ®tre / travailleurs)

> Pour pousser plus de charge, dÃ©marre 1 master + N workers.
> 

**Master :**

```bash
locust -f locustfile.py --master --headless \
  -u 1000 -r 100 -t 15m --host https://app.example.com --only-summary

```

**Workers :**

```bash
locust -f locustfile.py --worker --master-host 127.0.0.1
# (rÃ©pÃ©ter la commande sur plusieurs machines/containers)

```

Options utiles cÃ´tÃ© master :

- `-expect-workers N` : attend N workers avant de dÃ©marrer
- `-master-bind-host/--master-bind-port` : Ã©coute master personnalisÃ©e

---

### ðŸ§  Petits rappels utiles

- **Users (`u`)** = plateau de charge cible, **Spawn rate (`r`)** = pente de montÃ©e.
- **`-only-summary`** garde la console propre en CI (un verdict clair).
- Toujours fixer `-host` ou le dÃ©finir dans `HttpUser.host`.
- Pense Ã  `-stop-timeout` pour une fin de test propre (ex : 30 s).
- Combine `-csv` et `-html` pour conserver des **preuves** et **comparer** les runs.

---

### ðŸŽ¯ Pour aller plus loin
- [Documentation officielle Locust](https://docs.locust.io)
- [Exemples GitLab CI/CD Load Testing](https://docs.gitlab.com/ee/ci/testing/load_performance_testing.html)
- [Tutoriel vidÃ©o Locust & Python](https://www.youtube.com/results?search_query=locust+python+tutorial)

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---

---
[Module suivant â†’](M21_Artillery.md)
---
