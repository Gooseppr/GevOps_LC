---
titre: AWS Compute
type: module
jour: 25
ordre: 2
tags: aws, cloud, devops
---

## 1. Pourquoi le ‚Äúcompute‚Äù (puissance de calcul) est central ?

Toutes les entreprises ont besoin de **capacit√© de calcul** (*compute capacity*) pour faire tourner :

- sites web
- API
- batchs de traitement
- applications m√©tiers, bases de donn√©es, etc.

Avec AWS, au lieu d‚Äôacheter et g√©rer toi-m√™me des serveurs, tu consommes du **Compute as a Service** :

| Probl√®me traditionnel | En cloud (Compute as a Service) |
| --- | --- |
| Acheter du mat√©riel (CAPEX) | Tu loues de la capacit√© (OPEX / pay-as-you-go) |
| G√©rer l‚Äô√©lectricit√©, la clim, le r√©seau | AWS g√®re l‚Äôinfrastructure |
| Dimensionner pour le pic de charge | Tu peux **scaler** (scale up/down) |
| Besoin d‚Äôexpertise syst√®me forte | Tu te concentres sur l‚Äôapplication |

---

## 2. Les grandes familles de compute sur AWS

Quand tu dois choisir comment ex√©cuter ton application sur AWS, tu as 3 grandes options :

| Type | Id√©e g√©n√©rale | Services AWS typiques |
| --- | --- | --- |
| **Machines virtuelles (Virtual Machines / VMs)** | Tu g√®res un serveur (OS, packages, etc.). | Amazon EC2 |
| **Conteneurs (Containers)** | Tu empaquetes ton app avec ses d√©pendances. | ECS, EKS, Fargate |
| **Serverless Compute** | Tu fournis seulement le code ou la d√©finition de t√¢che. | Lambda, Fargate (serverless containers) |

---

## 3. Amazon EC2 ‚Äì Machines virtuelles dans le cloud

### 3.1. Principe

**Amazon EC2 (Elastic Compute Cloud)** = service qui permet de cr√©er des **instances** (EC2 instances), c‚Äôest-√†-dire des **machines virtuelles dans le cloud**.

Avec EC2, tu peux :

- **provisionner** (provision) et lancer des instances en quelques minutes ;
- **arr√™ter** (stop) ou **terminer** (terminate) une instance quand tu n‚Äôen as plus besoin ;
- payer **√† l‚Äôheure ou √† la seconde** (*per hour / per second* selon le type) ‚Üí **pay-as-you-go**.

Exemples d‚Äôusages :

‚Äì serveurs web, backends applicatifs, bases de donn√©es autog√©r√©es, jobs batch‚Ä¶

---

### 3.2. Facturation ‚ÄúPay as you go‚Äù

- Tu paies pour le temps o√π l‚Äôinstance est **en fonctionnement** (running).
- Quand tu **stoppes** (stop) l‚Äôinstance, tu ne paies plus la partie **compute**, mais les **volumes de stockage** (EBS) restent factur√©s.
- Quand tu **termines** (terminate), l‚Äôinstance dispara√Æt et son disque racine aussi (sauf configuration contraire).

---

### 3.3. AMI ‚Äì Amazon Machine Image

Une **AMI (Amazon Machine Image)** est un **mod√®le d‚Äôinstance** (template) qui contient :

- un syst√®me d‚Äôexploitation (Amazon Linux, Ubuntu, Windows, etc.)
- √©ventuellement des logiciels d√©j√† install√©s
- la config de disques, partitions, etc.

**Relation AMI ‚Üî EC2 instance** :

```
        +----------------------+
        |      AMI (image)     |
        | OS + config + soft   |
        +----------+-----------+
                   |
            "Launch instance"
                   v
        +----------------------+
        |    EC2 Instance      |  <- VM active
        +----------------------+
                   |
                   v
        +----------------------+
        |    Root volume (EBS) |
        +----------------------+

```

üëâ **Les instances EC2 sont des versions actives de ce qui est d√©fini dans une AMI.**

---

### 3.4. R√©utilisation d‚ÄôAMI

Processus classique :

```
AMI #1  --launch-->  EC2 Instance #1  --create image-->  AMI #2  --launch--> EC2 Instance #2

```

Tu peux :

1. Lancer une instance √† partir d‚Äôune AMI de base (AMI #1).
2. Configurer l‚ÄôOS, installer tes logiciels, ton app.
3. Cr√©er une **nouvelle AMI personnalis√©e** (AMI #2).
4. Relancer √† volont√© des instances identiques √† partir d‚ÄôAMI #2.

C‚Äôest tr√®s utilis√© en entreprise pour standardiser les serveurs.

---

### 3.5. D‚Äôo√π viennent les AMI ?

| Source | Description |
| --- | --- |
| **Quick Start AMIs** | Images fournies par AWS (ex : Amazon Linux). |
| **AWS Marketplace AMIs** | Images propos√©es par des √©diteurs (payantes ou non). |
| **Mes AMI / My AMIs** | AMI personnalis√©es que tu cr√©es toi-m√™me. |
| **AMI communautaires / Community AMIs** | Images partag√©es par d‚Äôautres utilisateurs. |

---

## 4. Types d‚Äôinstances et familles

### 4.1. Lecture d‚Äôun type d‚Äôinstance : `c5n.xlarge`

```
c5n.xlarge
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Taille de l‚Äôinstance (instance size)
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Attribut (network optimised, etc.)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Famille + g√©n√©ration (family + generation)

```

- **Famille (family)** : `c` ‚Üí **Compute optimised**
- **G√©n√©ration (generation)** : `5` ‚Üí 5e g√©n√©ration de la famille C
- **Attribut (attribute)** : `n` ‚Üí optimis√©e r√©seau (network optimised)
- **Taille (size)** : `xlarge` ‚Üí quantit√© de vCPU / RAM associ√©e

---

### 4.2. Familles d‚Äôinstances (Instance Families)

Chaque famille est optimis√©e pour un type de workload.

| Famille | Type FR / EN | Exemple de cas d‚Äôusage |
| --- | --- | --- |
| **M, T** | G√©n√©ralistes (General purpose) | petites applis web, serveurs d‚Äôapp, dev/test |
| **C** | Optimis√©es pour le calcul (Compute optimised) | traitement vid√©o, calcul scientifique, micro-services tr√®s CPU |
| **R, X, Z** | Optimis√©es m√©moire (Memory optimised) | bases de donn√©es en m√©moire, caches, gros traitements analytics |
| **P, G, Trn, DL, F, VT** | Calcul acc√©l√©r√© (Accelerated computing, GPU / FPGA) | machine learning, rendu 3D, HPC, encodage vid√©o |
| **I, Im, Is, D, H** | Optimis√©es stockage (Storage optimised) | bases de donn√©es NoSQL, data lakes, workload IO intensif |
| **Hpc** | Calcul haute performance (High Performance Computing) | simulations scientifiques, mod√©lisation, CFD |

Tu peux t‚Äôen servir √† l‚Äôoral : ‚Äú**For CPU-bound workloads, we usually pick C-family instances like c5 or c6g**‚Äù.

---

### 4.3. Localisation des instances EC2

Par d√©faut, quand tu lances une instance :

- elle est d√©ploy√©e dans un **VPC (Virtual Private Cloud)**, souvent le **VPC par d√©faut** si tu n‚Äôen choisis pas ;
- tu peux choisir l‚Äô**Availability Zone** (ex : `eu-west-3a`) et les sous-r√©seaux (subnets).

---

### 4.4. Scalabilit√© (Scalability) avec EC2

**Scalabilit√© / Scalability** = capacit√© d‚Äôun syst√®me √† **augmenter ou diminuer** sa capacit√© de traitement quand la charge varie.

Deux formes :

| Type | FR | EN | Exemple |
| --- | --- | --- | --- |
| Verticale | Scale up / down | Modifier la taille de l‚Äôinstance | passer de `t3.small` √† `t3.large` |
| Horizontale | Scale out / in | Ajouter / retirer des instances | passer de 2 √† 6 serveurs web |

Avec EC2, tu peux :

- utiliser les **APIs** pour cr√©er / d√©truire des instances ;
- utiliser **Auto Scaling Groups** pour scaler automatiquement selon CPU, nombre de requ√™tes, etc.

---

### 4.5. Cycle de vie d‚Äôune instance (Instance Lifecycle)

```
pending (lancement)
   ‚Üì
running (en fonctionnement)
   ‚Üì   ‚Üò
stopping  rebooting
   ‚Üì
stopped
   ‚Üì
terminated

```

- **pending** : AWS pr√©pare l‚Äôinstance.
- **running** : l‚Äôinstance tourne ‚Üí facturation compute.
- **stopping/stopped** : arr√™t, plus de compute factur√© (mais stockage oui).
- **terminated** : instance d√©truite.

---

## 5. Conteneurs (Containers) sur AWS

### 5.1. Rappel VM vs Conteneurs

| Aspect | Virtual Machine (VM) | Container |
| --- | --- | --- |
| Contenu | OS complet + app | App + d√©pendances uniquement |
| Isolation | Niveau OS (hyperviseur) | Niveau processus (namespace, cgroups) |
| D√©marrage | Plut√¥t lent (minutes) | Rapide (secondes) |
| Poids | Lourd (Go) | L√©ger (Mo) |
| Densit√© | Moins de VMs par serveur | Beaucoup de containers par serveur |
| Exemples AWS | EC2 | ECS, EKS, Fargate |

Une VM contient **l‚Äôapplication + un OS invit√©** (Guest OS).

Un container ne contient **que l‚Äôapplication et ses d√©pendances**, et partage le noyau (kernel) de l‚ÄôOS h√¥te.

---

### 5.2. Services de conteneurs sur AWS

- **Amazon ECS (Elastic Container Service)** : orchestrateur de conteneurs ‚Äúmade in AWS‚Äù.
- **Amazon EKS (Elastic Kubernetes Service)** : Kubernetes manag√© par AWS.
- **AWS Fargate** : mode de compute **serverless pour conteneurs** (utilis√© avec ECS ou EKS).

---

## 6. ECS ‚Äì Amazon Elastic Container Service

ECS fournit une structure logique que tu peux sch√©matiser ainsi :

```
Cluster
 ‚îî‚îÄ Service
     ‚îî‚îÄ Task
         ‚îî‚îÄ Container(s)
             ‚îî‚îÄ Image Docker

```

| Concept | R√¥le FR / EN |
| --- | --- |
| **Cluster** | Groupe logique de ressources / services (cluster) dans une r√©gion. |
| **Service** | Maintient un nombre d√©sir√© de t√¢ches (service) : remplace les tasks en √©chec. |
| **Task** | Unit√© d‚Äôex√©cution compos√©es d‚Äôun ou plusieurs containers (task). |
| **Task definition** | Mod√®le JSON d√©crivant l‚Äôapplication (image, CPU, m√©moire, ports‚Ä¶). |
| **Compute** | EC2, EC2 Spot, Fargate, Fargate Spot. |

---

### 6.1. Exemple de d√©finition de t√¢che ECS

Tu avais :

```json
{
  "family": "webserver",
  "containerDefinitions": [
    {
      "name": "web",
      "image": "nginx",
      "memory": "100",
      "cpu": "99"
    }
  ],
  "requiresCompatibilities": ["FARGATE"],
  "networkMode": "awsvpc",
  "memory": "512",
  "cpu": "256"
}

```

D√©cryptage ligne par ligne :

| Champ | Explication FR | EN |
| --- | --- | --- |
| `family` | Nom logique de la famille de t√¢ches, comme un ‚Äútemplate name‚Äù. | Task family name |
| `containerDefinitions` | Liste des containers qui composent la t√¢che. | Container definitions |
| `name` | Nom du conteneur dans la t√¢che. | Container name |
| `image` | Image Docker √† utiliser (ici `nginx`). | Docker image |
| `memory` (dans le container) | M√©moire r√©serv√©e pour ce conteneur. | Container memory |
| `cpu` (dans le container) | Part de CPU allou√©e √† ce conteneur. | Container CPU units |
| `requiresCompatibilities` | Mode d‚Äôex√©cution : ici **FARGATE** (serverless containers). | Launch type |
| `networkMode: "awsvpc"` | Chaque t√¢che obtient une **ENI** (carte r√©seau) d√©di√©e. | Network mode |
| `memory` (au niveau t√¢che) | M√©moire totale pour la t√¢che. | Task memory |
| `cpu` (au niveau t√¢che) | CPU total pour la t√¢che. | Task CPU |

---

## 7. EKS ‚Äì Amazon Elastic Kubernetes Service

Si tu utilises d√©j√† **Kubernetes**, EKS est :

> Un service manag√© qui cr√©e et g√®re le control plane Kubernetes pour toi.
> 
- Tu gardes les concepts Kubernetes : **pods, deployments, services, namespaces‚Ä¶**
- Tu n‚Äôadministres pas l‚ÄôETCD, l‚ÄôAPI server, etc.
- Tu peux ex√©cuter les worker nodes sur **EC2** ou en **Fargate**.

Rappel important √† l‚Äôoral :

> In Kubernetes, a pod is the smallest deployable unit. On EKS, a container runs inside a pod.
> 

---

## 8. Serverless Compute

‚Äú**Serverless**‚Äù = tu ne g√®res **pas les serveurs** : pas de gestion d‚ÄôOS, de patch, de scaling manuel.

Tu fournis uniquement :

- du **code** (Lambda)
- ou une **d√©finition de t√¢che** (Fargate)

AWS g√®re :

- l‚Äôinfrastructure
- le provisioning
- la mont√©e en charge
- la tol√©rance aux pannes

Avantages :

- facturation ultra granulaire (√† la requ√™te / √† la seconde)
- z√©ro gestion de serveurs
- tr√®s adapt√© aux workloads **√©v√®nementiels** (event-driven).

---

### 8.1. AWS Fargate

**Fargate** = moteur de compute serverless pour conteneurs ECS/EKS.

Tu d√©finis :

- l‚Äôimage de container
- la m√©moire / CPU
- le r√©seau et IAM

AWS g√®re :

- les serveurs sous-jacents
- la capacit√©
- le patching
- le scaling

Use cases typiques :

- microservices containeris√©s
- APIs en conteneurs
- traitements batch r√©guliers ou fr√©quents

---

### 8.2. AWS Lambda

**Lambda** = ex√©cution de **fonctions** serverless.

Caract√©ristiques :

- Tu √©cris une **fonction** (Node, Python, Java, Go, etc.).
- Tu d√©finis la **m√©moire** et √©ventuellement le **timeout**.
- Tu relies la fonction √† un **√©v√®nement** :
    - upload S3
    - message SQS
    - appel API Gateway
    - √©v√©nement EventBridge, etc.

Tu paies pour :

- le **nombre d‚Äôappels** (requests)
- la **dur√©e d‚Äôex√©cution** * temps m√©moire (GB-seconds)

Typiquement utilis√© pour :

- t√¢ches ponctuelles
- automatisations d‚Äôinfra
- ETL l√©gers
- backends simples d‚ÄôAPI

---

### 8.3. Fargate vs Lambda

| Crit√®re | Fargate | Lambda |
| --- | --- | --- |
| Type de workload | Containers | Fonctions |
| Dur√©e max | Longue (t√¢ches longues) | Limite (quelques minutes) |
| Gestion du runtime | Tu g√®res via l‚Äôimage Docker | AWS g√®re le runtime fonction |
| D√©marrage | Plus lent (pull image) | Tr√®s rapide (surtout si warm) |
| Complexit√© | Orchestration ECS/EKS | Simpler units (functions) |
| Cas typiques | Microservices, jobs batch importants | T√¢ches ponctuelles, cron, glue autour des services |

---

## 9. Sc√©narios d‚Äôexamen ‚Äì Analyse d√©taill√©e

### 9.1. Sc√©nario 1 ‚Äì Chargement trimestriel d‚Äôarticles (S3 ‚Üí DB)

> √ânonc√© :
> 
> 
> Vous √™tes d√©veloppeur et devez automatiser le chargement d'articles dans une base de donn√©es d'une boutique en ligne h√©berg√©e sur EC2. L'objectif est de charger les donn√©es d'un fichier d'inventaire t√©l√©charg√© sur Amazon S3 dans la base de donn√©es. La mise √† jour de l'inventaire se fait une fois par trimestre. Quel service de calcul AWS utiliseriez-vous pour h√©berger la logique de traitement ?
> 
> Options : EC2, ECS, EKS, AWS Lambda.
> 
> **Bonne r√©ponse : AWS Lambda.**
> 

**Pourquoi Lambda ?**

- La t√¢che est **√©v√®nementielle** : ‚Äúquand un fichier arrive dans S3, lancer un traitement‚Äù.
- La fr√©quence est **tr√®s faible** : une fois par trimestre.
- On ne veut pas payer un serveur 24/7 pour quelques minutes de traitement par an.
- Lambda s‚Äôint√®gre **nativement** avec S3 (S3 event ‚Üí Lambda trigger).
- Facturation √† l‚Äô**ex√©cution** uniquement ‚Üí parfait pour ce cas.

**Pourquoi pas EC2 ?**

- Il faudrait garder une instance EC2 disponible, g√©rer l‚ÄôOS, les patchs, etc.
- M√™me en la d√©marrant √† la demande, c‚Äôest plus complexe (cron, scripts d‚Äôautomatisation).
- Overkill pour un job trimestriel.

**Pourquoi pas ECS / EKS ?**

- ECS/EKS sont faits pour des workloads **containeris√©s**, souvent continus ou fr√©quents.
- Tu devrais g√©rer la d√©finition de t√¢che, le cluster, etc., ce qui alourdit √©norm√©ment pour un traitement tr√®s ponctuel.
- Lambda est la solution la plus simple et la moins ch√®re pour un **ETL trimestriel**.

> Formulation orale possible :
> 
> 
> *‚ÄúBecause the job runs only once a quarter and is triggered by an S3 upload, AWS Lambda is the best fit: event-driven, fully managed and pay-per-execution. EC2, ECS and EKS would require managing long-lived infrastructure for a very low-frequency task.‚Äù*
> 

---

### 9.2. Sc√©nario 2 ‚Äì Migration d‚Äôune appli Linux on-prem vers AWS

> √ânonc√© :
> 
> 
> Vous devez migrer une application h√©berg√©e dans votre centre de donn√©es sur site vers AWS. Elle fonctionne actuellement sur des serveurs Linux et vous souhaitez minimiser le refactoring. L'application doit √™tre √©lastique pour supporter une demande variable. Quelle option de calcul choisiriez-vous ?
> 
> Options : EC2, ECS, EKS, AWS Lambda.
> 
> **Bonne r√©ponse : EC2.**
> 

**Pourquoi EC2 ?**

- Tu veux **minimiser le refactoring** :
    - ton app tourne d√©j√† sur une **VM Linux** ‚Üí EC2 est presque √©quivalent √† ton serveur actuel.
    - tu peux quasiment **rejouer la m√™me config** (packages, services systemd, etc.).
- Tu peux obtenir l‚Äô**√©lasticit√©** (elasticity) en :
    - pla√ßant ton app derri√®re un **load balancer**
    - utilisant un **Auto Scaling Group** pour ajouter / retirer des instances.

Donc **lift-and-shift** id√©al : on d√©place plus ou moins tel quel sur EC2.

**Pourquoi pas Lambda ?**

- Lambda est adapt√© √† une app d√©coup√©e en **fonctions stateless**.
- Migrer une app monolithique Linux en Lambda demanderait **√©norm√©ment de refactoring** (d√©coupe, adaptation des runtimes, limites de dur√©e, etc.).
- L‚Äô√©nonc√© dit explicitement ‚Äúminimiser le refactoring‚Äù ‚Üí Lambda ne convient pas.

**Pourquoi pas ECS/EKS ?**

- Les conteneurs sont une bonne cible long terme, mais :
    - il faudrait **containeriser** l‚Äôapplication (Dockerfile, configuration, etc.) ;
    - mettre en place un orchestrateur (ECS ou EKS).
- C‚Äôest tr√®s bien pour une modernisation, mais **plus complexe** qu‚Äôun simple lift-and-shift sur EC2.
- Donc pour une premi√®re √©tape rapide ‚Üí EC2 est la meilleure option.

> Formulation orale :
> 
> 
> *‚ÄúSince the application already runs on Linux servers and we want to minimize refactoring, EC2 is the most appropriate choice. It allows a lift-and-shift migration with elasticity via Auto Scaling, whereas Lambda or container orchestrators like ECS/EKS would require significant redesign and containerization work.‚Äù*
>

---
[‚Üê Module pr√©c√©dent](M25_AWS_intro.md)
---
