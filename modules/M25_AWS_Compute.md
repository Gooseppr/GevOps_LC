---
titre: AWS Compute
type: module
jour: 25
ordre: 2
tags: aws, cloud, devops
---

# ğŸŸ¦ **Cours AWS Compute**

## 1. Pourquoi le â€œcomputeâ€ (puissance de calcul) est central ?

Toutes les entreprises ont besoin de **capacitÃ© de calcul** (*compute capacity*) pour faire tourner :

- sites web
- API
- batchs de traitement
- applications mÃ©tiers, bases de donnÃ©es, etc.

Avec AWS, au lieu dâ€™acheter et gÃ©rer toi-mÃªme des serveurs, tu consommes du **Compute as a Service** :

| ProblÃ¨me traditionnel | En cloud (Compute as a Service) |
| --- | --- |
| Acheter du matÃ©riel (CAPEX) | Tu loues de la capacitÃ© (OPEX / pay-as-you-go) |
| GÃ©rer lâ€™Ã©lectricitÃ©, la clim, le rÃ©seau | AWS gÃ¨re lâ€™infrastructure |
| Dimensionner pour le pic de charge | Tu peux **scaler** (scale up/down) |
| Besoin dâ€™expertise systÃ¨me forte | Tu te concentres sur lâ€™application |

---

## 2. Les grandes familles de compute sur AWS

Quand tu dois choisir comment exÃ©cuter ton application sur AWS, tu as 3 grandes options :

| Type | IdÃ©e gÃ©nÃ©rale | Services AWS typiques |
| --- | --- | --- |
| **Machines virtuelles (Virtual Machines / VMs)** | Tu gÃ¨res un serveur (OS, packages, etc.). | Amazon EC2 |
| **Conteneurs (Containers)** | Tu empaquetes ton app avec ses dÃ©pendances. | ECS, EKS, Fargate |
| **Serverless Compute** | Tu fournis seulement le code ou la dÃ©finition de tÃ¢che. | Lambda, Fargate (serverless containers) |

---

## 3. Amazon EC2 â€“ Machines virtuelles dans le cloud

### 3.1. Principe

**Amazon EC2 (Elastic Compute Cloud)** = service qui permet de crÃ©er des **instances** (EC2 instances), câ€™est-Ã -dire des **machines virtuelles dans le cloud**.

Avec EC2, tu peux :

- **provisionner** (provision) et lancer des instances en quelques minutes ;
- **arrÃªter** (stop) ou **terminer** (terminate) une instance quand tu nâ€™en as plus besoin ;
- payer **Ã  lâ€™heure ou Ã  la seconde** (*per hour / per second* selon le type) â†’ **pay-as-you-go**.

Exemples dâ€™usages :

â€“ serveurs web, backends applicatifs, bases de donnÃ©es autogÃ©rÃ©es, jobs batchâ€¦

---

### 3.2. Facturation â€œPay as you goâ€

- Tu paies pour le temps oÃ¹ lâ€™instance est **en fonctionnement** (running).
- Quand tu **stoppes** (stop) lâ€™instance, tu ne paies plus la partie **compute**, mais les **volumes de stockage** (EBS) restent facturÃ©s.
- Quand tu **termines** (terminate), lâ€™instance disparaÃ®t et son disque racine aussi (sauf configuration contraire).

---

### 3.3. AMI â€“ Amazon Machine Image

Une **AMI (Amazon Machine Image)** est un **modÃ¨le dâ€™instance** (template) qui contient :

- un systÃ¨me dâ€™exploitation (Amazon Linux, Ubuntu, Windows, etc.)
- Ã©ventuellement des logiciels dÃ©jÃ  installÃ©s
- la config de disques, partitions, etc.

**Relation AMI â†” EC2 instance** :

```
        +----------------------+
        |      AMI (image)     |
        | OS + config + soft   |
        +----------+-----------+
                   |
            "Launch instance"
                   v
        +----------------------+
        |    EC2 Instance      |  <- VM active
        +----------------------+
                   |
                   v
        +----------------------+
        |    Root volume (EBS) |
        +----------------------+

```

ğŸ‘‰ **Les instances EC2 sont des versions actives de ce qui est dÃ©fini dans une AMI.**

---

### 3.4. RÃ©utilisation dâ€™AMI

Processus classique :

```
AMI #1  --launch-->  EC2 Instance #1  --create image-->  AMI #2  --launch--> EC2 Instance #2

```

Tu peux :

1. Lancer une instance Ã  partir dâ€™une AMI de base (AMI #1).
2. Configurer lâ€™OS, installer tes logiciels, ton app.
3. CrÃ©er une **nouvelle AMI personnalisÃ©e** (AMI #2).
4. Relancer Ã  volontÃ© des instances identiques Ã  partir dâ€™AMI #2.

Câ€™est trÃ¨s utilisÃ© en entreprise pour standardiser les serveurs.

---

### 3.5. Dâ€™oÃ¹ viennent les AMI ?

| Source | Description |
| --- | --- |
| **Quick Start AMIs** | Images fournies par AWS (ex : Amazon Linux). |
| **AWS Marketplace AMIs** | Images proposÃ©es par des Ã©diteurs (payantes ou non). |
| **Mes AMI / My AMIs** | AMI personnalisÃ©es que tu crÃ©es toi-mÃªme. |
| **AMI communautaires / Community AMIs** | Images partagÃ©es par dâ€™autres utilisateurs. |

---

## 4. Types dâ€™instances et familles

### 4.1. Lecture dâ€™un type dâ€™instance : `c5n.xlarge`

```
c5n.xlarge
â”‚ â”‚ â””â”€â”€â”€â”€â”€ Taille de lâ€™instance (instance size)
â”‚ â””â”€â”€â”€â”€â”€â”€â”€ Attribut (network optimised, etc.)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ Famille + gÃ©nÃ©ration (family + generation)

```

- **Famille (family)** : `c` â†’ **Compute optimised**
- **GÃ©nÃ©ration (generation)** : `5` â†’ 5e gÃ©nÃ©ration de la famille C
- **Attribut (attribute)** : `n` â†’ optimisÃ©e rÃ©seau (network optimised)
- **Taille (size)** : `xlarge` â†’ quantitÃ© de vCPU / RAM associÃ©e

---

### 4.2. Familles dâ€™instances (Instance Families)

Chaque famille est optimisÃ©e pour un type de workload.

| Famille | Type FR / EN | Exemple de cas dâ€™usage |
| --- | --- | --- |
| **M, T** | GÃ©nÃ©ralistes (General purpose) | petites applis web, serveurs dâ€™app, dev/test |
| **C** | OptimisÃ©es pour le calcul (Compute optimised) | traitement vidÃ©o, calcul scientifique, micro-services trÃ¨s CPU |
| **R, X, Z** | OptimisÃ©es mÃ©moire (Memory optimised) | bases de donnÃ©es en mÃ©moire, caches, gros traitements analytics |
| **P, G, Trn, DL, F, VT** | Calcul accÃ©lÃ©rÃ© (Accelerated computing, GPU / FPGA) | machine learning, rendu 3D, HPC, encodage vidÃ©o |
| **I, Im, Is, D, H** | OptimisÃ©es stockage (Storage optimised) | bases de donnÃ©es NoSQL, data lakes, workload IO intensif |
| **Hpc** | Calcul haute performance (High Performance Computing) | simulations scientifiques, modÃ©lisation, CFD |

Tu peux tâ€™en servir Ã  lâ€™oral : â€œ**For CPU-bound workloads, we usually pick C-family instances like c5 or c6g**â€.

---

### 4.3. Localisation des instances EC2

Par dÃ©faut, quand tu lances une instance :

- elle est dÃ©ployÃ©e dans un **VPC (Virtual Private Cloud)**, souvent le **VPC par dÃ©faut** si tu nâ€™en choisis pas ;
- tu peux choisir lâ€™**Availability Zone** (ex : `eu-west-3a`) et les sous-rÃ©seaux (subnets).

---

### 4.4. ScalabilitÃ© (Scalability) avec EC2

**ScalabilitÃ© / Scalability** = capacitÃ© dâ€™un systÃ¨me Ã  **augmenter ou diminuer** sa capacitÃ© de traitement quand la charge varie.

Deux formes :

| Type | FR | EN | Exemple |
| --- | --- | --- | --- |
| Verticale | Modifier la taille de lâ€™instance | Scale up / down | passer de `t3.small` Ã  `t3.large` |
| Horizontale | Ajouter / retirer des instances | Scale out / in | passer de 2 Ã  6 serveurs web |

Avec EC2, tu peux :

- utiliser les **APIs** pour crÃ©er / dÃ©truire des instances ;
- utiliser **Auto Scaling Groups** pour scaler automatiquement selon CPU, nombre de requÃªtes, etc.

---

### 4.5. Cycle de vie dâ€™une instance (Instance Lifecycle)

```
pending (lancement)
   â†“
running (en fonctionnement)
   â†“   â†˜
stopping  rebooting
   â†“
stopped
   â†“
terminated

```

- **pending** : AWS prÃ©pare lâ€™instance.
- **running** : lâ€™instance tourne â†’ facturation compute.
- **stopping/stopped** : arrÃªt, plus de compute facturÃ© (mais stockage oui).
- **terminated** : instance dÃ©truite.

---

## 5. Conteneurs (Containers) sur AWS

### 5.1. Rappel VM vs Conteneurs

| Aspect | Virtual Machine (VM) | Container |
| --- | --- | --- |
| Contenu | OS complet + app | App + dÃ©pendances uniquement |
| Isolation | Niveau OS (hyperviseur) | Niveau processus (namespace, cgroups) |
| DÃ©marrage | PlutÃ´t lent (minutes) | Rapide (secondes) |
| Poids | Lourd (Go) | LÃ©ger (Mo) |
| DensitÃ© | Moins de VMs par serveur | Beaucoup de containers par serveur |
| Exemples AWS | EC2 | ECS, EKS, Fargate |

Une VM contient **lâ€™application + un OS invitÃ©** (Guest OS).

Un container ne contient **que lâ€™application et ses dÃ©pendances**, et partage le noyau (kernel) de lâ€™OS hÃ´te.

---

### 5.2. Services de conteneurs sur AWS

- **Amazon ECS (Elastic Container Service)** : orchestrateur de conteneurs â€œmade in AWSâ€.
- **Amazon EKS (Elastic Kubernetes Service)** : Kubernetes managÃ© par AWS.
- **AWS Fargate** : mode de compute **serverless pour conteneurs** (utilisÃ© avec ECS ou EKS).

---

## 6. ECS â€“ Amazon Elastic Container Service

ECS fournit une structure logique que tu peux schÃ©matiser ainsi :

```
Cluster
 â””â”€ Service
     â””â”€ Task
         â””â”€ Container(s)
             â””â”€ Image Docker

```

| Concept | RÃ´le FR / EN |
| --- | --- |
| **Cluster** | Groupe logique de ressources / services (cluster) dans une rÃ©gion. |
| **Service** | Maintient un nombre dÃ©sirÃ© de tÃ¢ches (service) : remplace les tasks en Ã©chec. |
| **Task** | UnitÃ© dâ€™exÃ©cution composÃ©es dâ€™un ou plusieurs containers (task). |
| **Task definition** | ModÃ¨le JSON dÃ©crivant lâ€™application (image, CPU, mÃ©moire, portsâ€¦). |
| **Compute** | EC2, EC2 Spot, Fargate, Fargate Spot. |

---

### 6.1. Exemple de dÃ©finition de tÃ¢che ECS

Tu avais :

```json
{
  "family": "webserver",
  "containerDefinitions": [
    {
      "name": "web",
      "image": "nginx",
      "memory": "100",
      "cpu": "99"
    }
  ],
  "requiresCompatibilities": ["FARGATE"],
  "networkMode": "awsvpc",
  "memory": "512",
  "cpu": "256"
}

```

DÃ©cryptage ligne par ligne :

| Champ | Explication FR | EN |
| --- | --- | --- |
| `family` | Nom logique de la famille de tÃ¢ches, comme un â€œtemplate nameâ€. | Task family name |
| `containerDefinitions` | Liste des containers qui composent la tÃ¢che. | Container definitions |
| `name` | Nom du conteneur dans la tÃ¢che. | Container name |
| `image` | Image Docker Ã  utiliser (ici `nginx`). | Docker image |
| `memory` (dans le container) | MÃ©moire rÃ©servÃ©e pour ce conteneur. | Container memory |
| `cpu` (dans le container) | Part de CPU allouÃ©e Ã  ce conteneur. | Container CPU units |
| `requiresCompatibilities` | Mode dâ€™exÃ©cution : ici **FARGATE** (serverless containers). | Launch type |
| `networkMode: "awsvpc"` | Chaque tÃ¢che obtient une **ENI** (carte rÃ©seau) dÃ©diÃ©e. | Network mode |
| `memory` (au niveau tÃ¢che) | MÃ©moire totale pour la tÃ¢che. | Task memory |
| `cpu` (au niveau tÃ¢che) | CPU total pour la tÃ¢che. | Task CPU |

---

## 7. EKS â€“ Amazon Elastic Kubernetes Service

Si tu utilises dÃ©jÃ  **Kubernetes**, EKS est :

> Un service managÃ© qui crÃ©e et gÃ¨re le control plane Kubernetes pour toi.
> 
- Tu gardes les concepts Kubernetes : **pods, deployments, services, namespacesâ€¦**
- Tu nâ€™administres pas lâ€™ETCD, lâ€™API server, etc.
- Tu peux exÃ©cuter les worker nodes sur **EC2** ou en **Fargate**.

Rappel important Ã  lâ€™oral :

> In Kubernetes, a pod is the smallest deployable unit. On EKS, a container runs inside a pod.
> 

---

## 8. Serverless Compute

â€œ**Serverless**â€ = tu ne gÃ¨res **pas les serveurs** : pas de gestion dâ€™OS, de patch, de scaling manuel.

Tu fournis uniquement :

- du **code** (Lambda)
- ou une **dÃ©finition de tÃ¢che** (Fargate)

AWS gÃ¨re :

- lâ€™infrastructure
- le provisioning
- la montÃ©e en charge
- la tolÃ©rance aux pannes

Avantages :

- facturation ultra granulaire (Ã  la requÃªte / Ã  la seconde)
- zÃ©ro gestion de serveurs
- trÃ¨s adaptÃ© aux workloads **Ã©vÃ¨nementiels** (event-driven).

---

### 8.1. AWS Fargate

**Fargate** = moteur de compute serverless pour conteneurs ECS/EKS.

Tu dÃ©finis :

- lâ€™image de container
- la mÃ©moire / CPU
- le rÃ©seau et IAM

AWS gÃ¨re :

- les serveurs sous-jacents
- la capacitÃ©
- le patching
- le scaling

Use cases typiques :

- microservices containerisÃ©s
- APIs en conteneurs
- traitements batch rÃ©guliers ou frÃ©quents

---

### 8.2. AWS Lambda

**Lambda** = exÃ©cution de **fonctions** serverless.

CaractÃ©ristiques :

- Tu Ã©cris une **fonction** (Node, Python, Java, Go, etc.).
- Tu dÃ©finis la **mÃ©moire** et Ã©ventuellement le **timeout**.
- Tu relies la fonction Ã  un **Ã©vÃ¨nement** :
    - upload S3
    - message SQS
    - appel API Gateway
    - Ã©vÃ©nement EventBridge, etc.

Tu paies pour :

- le **nombre dâ€™appels** (requests)
- la **durÃ©e dâ€™exÃ©cution** * temps mÃ©moire (GB-seconds)

Typiquement utilisÃ© pour :

- tÃ¢ches ponctuelles
- automatisations dâ€™infra
- ETL lÃ©gers
- backends simples dâ€™API

---

### 8.3. Fargate vs Lambda

| CritÃ¨re | Fargate | Lambda |
| --- | --- | --- |
| Type de workload | Containers | Fonctions |
| DurÃ©e max | Longue (tÃ¢ches longues) | Limite (quelques minutes) |
| Gestion du runtime | Tu gÃ¨res via lâ€™image Docker | AWS gÃ¨re le runtime fonction |
| DÃ©marrage | Plus lent (pull image) | TrÃ¨s rapide (surtout si warm) |
| ComplexitÃ© | Orchestration ECS/EKS | Simpler units (functions) |
| Cas typiques | Microservices, jobs batch importants | TÃ¢ches ponctuelles, cron, glue autour des services |

---

## 9. ScÃ©narios dâ€™examen â€“ Analyse dÃ©taillÃ©e

### 9.1. ScÃ©nario 1 â€“ Chargement trimestriel dâ€™articles (S3 â†’ DB)

> Ã‰noncÃ© :
> 
> 
> Vous Ãªtes dÃ©veloppeur et devez automatiser le chargement d'articles dans une base de donnÃ©es d'une boutique en ligne hÃ©bergÃ©e sur EC2. L'objectif est de charger les donnÃ©es d'un fichier d'inventaire tÃ©lÃ©chargÃ© sur Amazon S3 dans la base de donnÃ©es. La mise Ã  jour de l'inventaire se fait une fois par trimestre. Quel service de calcul AWS utiliseriez-vous pour hÃ©berger la logique de traitement ?
> 
> Options : EC2, ECS, EKS, AWS Lambda.
> 
> **Bonne rÃ©ponse : AWS Lambda.**
> 

**Pourquoi Lambda ?**

- La tÃ¢che est **Ã©vÃ¨nementielle** : â€œquand un fichier arrive dans S3, lancer un traitementâ€.
- La frÃ©quence est **trÃ¨s faible** : une fois par trimestre.
- On ne veut pas payer un serveur 24/7 pour quelques minutes de traitement par an.
- Lambda sâ€™intÃ¨gre **nativement** avec S3 (S3 event â†’ Lambda trigger).
- Facturation Ã  lâ€™**exÃ©cution** uniquement â†’ parfait pour ce cas.

**Pourquoi pas EC2 ?**

- Il faudrait garder une instance EC2 disponible, gÃ©rer lâ€™OS, les patchs, etc.
- MÃªme en la dÃ©marrant Ã  la demande, câ€™est plus complexe (cron, scripts dâ€™automatisation).
- Overkill pour un job trimestriel.

**Pourquoi pas ECS / EKS ?**

- ECS/EKS sont faits pour des workloads **containerisÃ©s**, souvent continus ou frÃ©quents.
- Tu devrais gÃ©rer la dÃ©finition de tÃ¢che, le cluster, etc., ce qui alourdit Ã©normÃ©ment pour un traitement trÃ¨s ponctuel.
- Lambda est la solution la plus simple et la moins chÃ¨re pour un **ETL trimestriel**.

> Formulation orale possible :
> 
> 
> *â€œBecause the job runs only once a quarter and is triggered by an S3 upload, AWS Lambda is the best fit: event-driven, fully managed and pay-per-execution. EC2, ECS and EKS would require managing long-lived infrastructure for a very low-frequency task.â€*
> 

---

### 9.2. ScÃ©nario 2 â€“ Migration dâ€™une appli Linux on-prem vers AWS

> Ã‰noncÃ© :
> 
> 
> Vous devez migrer une application hÃ©bergÃ©e dans votre centre de donnÃ©es sur site vers AWS. Elle fonctionne actuellement sur des serveurs Linux et vous souhaitez minimiser le refactoring. L'application doit Ãªtre Ã©lastique pour supporter une demande variable. Quelle option de calcul choisiriez-vous ?
> 
> Options : EC2, ECS, EKS, AWS Lambda.
> 
> **Bonne rÃ©ponse : EC2.**
> 

**Pourquoi EC2 ?**

- Tu veux **minimiser le refactoring** :
    - ton app tourne dÃ©jÃ  sur une **VM Linux** â†’ EC2 est presque Ã©quivalent Ã  ton serveur actuel.
    - tu peux quasiment **rejouer la mÃªme config** (packages, services systemd, etc.).
- Tu peux obtenir lâ€™**Ã©lasticitÃ©** (elasticity) en :
    - plaÃ§ant ton app derriÃ¨re un **load balancer**
    - utilisant un **Auto Scaling Group** pour ajouter / retirer des instances.

Donc **lift-and-shift** idÃ©al : on dÃ©place plus ou moins tel quel sur EC2.

**Pourquoi pas Lambda ?**

- Lambda est adaptÃ© Ã  une app dÃ©coupÃ©e en **fonctions stateless**.
- Migrer une app monolithique Linux en Lambda demanderait **Ã©normÃ©ment de refactoring** (dÃ©coupe, adaptation des runtimes, limites de durÃ©e, etc.).
- Lâ€™Ã©noncÃ© dit explicitement â€œminimiser le refactoringâ€ â†’ Lambda ne convient pas.

**Pourquoi pas ECS/EKS ?**

- Les conteneurs sont une bonne cible long terme, mais :
    - il faudrait **containeriser** lâ€™application (Dockerfile, configuration, etc.) ;
    - mettre en place un orchestrateur (ECS ou EKS).
- Câ€™est trÃ¨s bien pour une modernisation, mais **plus complexe** quâ€™un simple lift-and-shift sur EC2.
- Donc pour une premiÃ¨re Ã©tape rapide â†’ EC2 est la meilleure option.

> Formulation orale :
> 
> 
> *â€œSince the application already runs on Linux servers and we want to minimize refactoring, EC2 is the most appropriate choice. It allows a lift-and-shift migration with elasticity via Auto Scaling, whereas Lambda or container orchestrators like ECS/EKS would require significant redesign and containerization work.â€*
>

---
[â† Module prÃ©cÃ©dent](M25_AWS_intro.md) | [Module suivant â†’](M25_AWS_reponse-quizz.md)
---
