---
title: Monitoring avanc√©
sujet: Observabilit√©
type: module
jour: 38
ordre: 1
tags: prometheus, grafana, alertmanager, blackbox, observabilit√©, monitoring
---

# üéì Monitoring avanc√© ‚Äì Prometheus & Grafana

## Ce que tu sauras faire

√Ä la fin de ce cours, tu sauras :

- Mettre en place une **f√©d√©ration Prometheus** (central + leaf).
- Exporter des m√©triques vers un **stockage longue dur√©e** (Thanos, InfluxDB, Cortex‚Ä¶).
- Cr√©er et utiliser des **m√©triques personnalis√©es** dans ton code (Counter, Gauge, Histogram‚Ä¶).
- Configurer un **alerting avanc√©** avec Alertmanager (routing, grouping, inhibition, silences, `amtool`).
- Superviser tes services **depuis l‚Äôext√©rieur** avec le **Blackbox Exporter**.
- Construire des **dashboards Grafana avanc√©s** : multi data-sources, variables, liens entre dashboards.
- Comprendre comment articuler **m√©triques, logs et traces** dans une vraie strat√©gie d‚Äôobservabilit√©.

> Id√©e visuelle : pour l‚Äôarchitecture Prometheus, tu peux utiliser un graph mermaid (architecture) ou un flowchart dans ton markdown.
> 

---

## 1. Rappel ‚Äì Pourquoi ‚Äúmonitoring avanc√©‚Äù ?

Les premiers cours Prometheus / Grafana t‚Äôont donn√© les bases :

- Un serveur Prometheus qui scrape des cibles.
- Un Alertmanager qui envoie des mails / messages.
- Un Grafana branch√© sur Prometheus pour afficher des graphes.

√áa fonctionne tr√®s bien‚Ä¶ **tant que** :

- tu n‚Äôas pas 36 environnements (dev, stg, prod, clients A/B/C),
- tu n‚Äôas pas plusieurs datacenters ou clusters,
- tu ne gardes pas les m√©triques plus que quelques semaines,
- tu ne fais pas d‚Äôobservabilit√© ‚Äúcompl√®te‚Äù (m√©triques + logs + traces).

Ce module va donc t‚Äôapprendre √† passer du **laboratoire** √† quelque chose de plus proche de la **prod d‚Äôentreprise**.

---

## 2. F√©d√©ration Prometheus

### 2.1. Architecture en f√©d√©ration

D√®s que tu as plusieurs environnements ou clusters, une seule instance de Prometheus devient :

- un **goulot d‚Äô√©tranglement** (trop de cibles √† scrapper),
- un **risque de panne unique**,
- difficile √† dimensionner et √† sauvegarder.

On d√©coupe donc l‚Äôarchitecture :

- **Leaf Prometheus** (ou ‚Äúshard‚Äù)
    
    ‚ûú Prometheus locaux, **proches des applications**.
    
    Ils scrappent les exporters des VMs, pods, bases, etc.
    
- **Prometheus central (federation)**
    
    ‚ûú Ne scrappe **pas les apps directement**, mais les **Prometheus leaf** via `/federate`.
    
    Il n‚Äôimporte **qu‚Äôune partie** des m√©triques (les plus utiles pour une vue globale).
    

Sch√©ma possible en markdown :

```mermaid
graph LR
  subgraph Env1
    API1[api] --> Exp1[Exporter]
    DB1[psql] --> Exp2[Exporter]
    Leaf1[Prometheus Leaf 1]
    Exp1 --> Leaf1
    Exp2 --> Leaf1
  end

  subgraph Env2
    UI[ui] --> Exp3[Exporter]
    BACK[back] --> Exp4[Exporter]
    Leaf2[Prometheus Leaf 2]
    Exp3 --> Leaf2
    Exp4 --> Leaf2
  end

  Leaf1 -->|/federate| Central[(Prometheus Central)]
  Leaf2 -->|/federate| Central

```

Cha√Æne de collecte :

> Service ‚Üí Exporter ‚Üí Prometheus Leaf ‚Üí Prometheus Central
> 

### 2.2. Requ√™tes f√©d√©r√©es & configuration

Le Prometheus central **ne copie pas tout**.

Il interroge les leaf avec des requ√™tes filtr√©es, par exemple :

- ‚ÄúJe veux la m√©trique `up` pour le job `api`.‚Äù
- ‚ÄúJe veux les erreurs HTTP 5xx agr√©g√©es par cluster.‚Äù

Dans le `prometheus.yml` du **central** :

```yaml
scrape_configs:
  - job_name: 'leaf-federation'
    scrape_interval: 30s
    metrics_path: /federate
    params:
      'match[]':
        - '{job="api"}'
        - 'up'
        - 'rate(http_requests_total[5m])'
    static_configs:
      - targets:
          - 'leaf1:9090'
          - 'leaf2:9090'

```

Ici :

- `metrics_path: /federate` ‚ûú Prometheus sait qu‚Äôil s‚Äôagit d‚Äôune f√©d√©ration.
- `match[]` ‚ûú liste des expressions PromQL que tu veux importer.

Tu peux par exemple :

- importer `up{job="api"}` pour superviser la sant√© globale,
- importer `rate(http_requests_total[5m])` pour une vision trafic globale.

### 2.3. Avantages / limites

‚úÖ **Avantages :**

- Scalabilit√© : plusieurs Prometheus se partagent la charge.
- R√©silience : chaque leaf garde **son historique local**.
- Vue globale : le central devient **un point d‚Äôentr√©e unique** pour tes dashboards ou ton alerting.

‚ö†Ô∏è **Limites :**

- Le central **ne conna√Æt que ce qu‚Äôil importe** (pas l‚Äôhistorique complet).
- Si tu changes les expressions de f√©d√©ration, ton historique central change.
- Mauvaise id√©e d‚Äôimporter des s√©ries √† **haute cardinalit√©** (ex : label `user_id`).

üß† **Bonnes pratiques :**

- Utiliser la f√©d√©ration pour :
    - les **KPIs globaux**,
    - l‚Äô**alerting global**,
    - les **vues cross-cluster**.
- Garder les **analyses d√©taill√©es** sur les leaf.

---

## 3. Export de m√©triques & stockage longue dur√©e

### 3.1. Pourquoi exporter ?

Prometheus n‚Äôest pas con√ßu pour :

- stocker des ann√©es de donn√©es,
- faire du big data ou de l‚Äôanalytics massif.

Son travail : **scraper et r√©pondre vite**.

Pour l‚Äôhistorique long terme, on s‚Äôappuie sur des solutions sp√©cialis√©es :

- **Thanos** (extension Prometheus, stockage objet + requ√™tes distribu√©es),
- **Cortex / Mimir** (multi-tenant, tr√®s orient√© SaaS),
- **InfluxDB**, **VictoriaMetrics**, **AWS Timestream**, etc.

### 3.2. Remote Write / Remote Read

- `remote_write` ‚ûú Prometheus **pousse** ses samples vers une base externe.
- `remote_read` ‚ûú Prometheus **lit** des donn√©es externes **comme si elles √©taient √† lui**.

`prometheus.yml` simplifi√© avec InfluxDB :

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']

remote_write:
  - url: "http://influxdb:8086/api/v1/prom/write"
    remote_timeout: 30s
    write_relabel_configs:
      - source_labels: [__name__]
        regex: ".*"
        action: keep

remote_read:
  - url: "http://influxdb:8086/api/v1/prom/read"
    remote_timeout: 30s
    read_recent: true

```

Points importants :

- `write_relabel_configs` te permet de **filtrer** ce que tu exportes.
- Tu peux par exemple n‚Äôenvoyer que :
    - les m√©triques avec `env="prod"`,
    - les s√©ries de type `http_requests_total`, `cpu_usage_seconds_total`, etc.

### 3.3. Cas d‚Äôusage typiques

- **Infra prod** :
    - 15 jours de r√©tention dans Prometheus,
    - 1 an dans Thanos / Cortex.
- **Data / BI** :
    - dashboards mensuels sur 12 mois,
    - entra√Ænement de mod√®les ML sur des m√©triques historiques.
- **Audit / conformit√©** :
    - garder certains KPI de disponibilit√© plusieurs ann√©es.

üß† **Checklist :**

- [ ]  Choisir une base longue dur√©e adapt√©e (co√ªt, cloud, complexit√©).
- [ ]  D√©finir **quelles s√©ries** sont vraiment utiles long terme.
- [ ]  Monitorer la pipeline elle-m√™me (m√©triques export√©es / erreurs d‚Äô√©criture).

---

## 4. M√©triques personnalis√©es

### 4.1. Pourquoi ne pas se contenter des exporters ?

Les exporters (Node Exporter, cAdvisor, etc.) donnent :

- CPU, m√©moire, disque,
- m√©triques syst√®me, r√©seau, etc.

Mais **ton m√©tier** ne parle pas de ‚ÄúCPU √† 80 %‚Äù, il parle de :

- commandes trait√©es,
- paniers valid√©s,
- erreurs API,
- temps de r√©ponse, etc.

Les **m√©triques personnalis√©es** permettent d‚Äôexposer cette r√©alit√© m√©tier.

### 4.2. Clients Prometheus par langage

Quelques librairies standard :

| Langage | Client |
| --- | --- |
| Node.js | `prom-client` |
| Python | `prometheus_client` |
| Java | `simpleclient` |
| Go | support natif (`prometheus` package) |

### 4.3. Types de m√©triques

- **Counter**
    
    ‚ûú Compte uniquement vers le haut.
    
    Ex : `http_requests_total`, `orders_created_total`.
    
- **Gauge**
    
    ‚ûú Monte et descend.
    
    Ex : `connected_users`, `queue_length`.
    
- **Histogram**
    
    ‚ûú Distribue des valeurs dans des **buckets**.
    
    Ex : temps de r√©ponse r√©partis en tranches (0‚Äì100ms, 100‚Äì300ms‚Ä¶).
    
- **Summary**
    
    ‚ûú Fournit des quantiles (p50, p90‚Ä¶) calcul√©s c√¥t√© client.
    
    Moins pratique en f√©d√©ration, on pr√©f√®re souvent `Histogram`.
    

### 4.4. Exemple en Node.js (prom-client)

```jsx
const express = require('express');
const client = require('prom-client');

const app = express();
const register = new client.Registry();

// Counter : nombre total de requ√™tes HTTP
const httpRequestsTotal = new client.Counter({
  name: 'http_requests_total',
  help: 'Total des requ√™tes HTTP',
  labelNames: ['method', 'route', 'status']
});

// Histogram : dur√©e des requ√™tes HTTP
const httpRequestDuration = new client.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Dur√©e des requ√™tes HTTP en secondes',
  labelNames: ['route'],
  buckets: [0.05, 0.1, 0.3, 0.5, 1, 3]
});

register.registerMetric(httpRequestsTotal);
register.registerMetric(httpRequestDuration);

// Middleware d'instrumentation
app.use((req, res, next) => {
  const end = httpRequestDuration.startTimer({ route: req.path });

  res.on('finish', () => {
    httpRequestsTotal.inc({
      method: req.method,
      route: req.path,
      status: res.statusCode
    });
    end(); // enregistre la dur√©e
  });

  next();
});

// Endpoint m√©tier
app.get('/api/hello', (req, res) => {
  res.json({ message: 'Hello' });
});

// Endpoint /metrics
app.get('/metrics', async (req, res) => {
  res.set('Content-Type', register.contentType);
  res.end(await register.metrics());
});

app.listen(3000);

```

Prometheus n‚Äôa plus qu‚Äô√† scrapper `http://service:3000/metrics`.

### 4.5. Bonnes pratiques

- **Noms clairs** : `app_orders_total`, `api_errors_total`, etc.
- **Labels stables** : pas de `user_id`, `request_id`, `email`‚Ä¶ ‚Üí sinon **explosion de cardinalit√©**.
- **Unit√©s explicites** dans le nom :
    - `_seconds`, `_bytes`, `_total`, etc.

---

## 5. Alerting avanc√© avec Alertmanager

L‚Äôobjectif n‚Äôest pas d‚Äôavoir **plus d‚Äôalertes**, mais des alertes :

- pertinentes,
- bien rout√©es,
- regroup√©es,
- silenc√©es au bon moment.

### 5.1. Rappel du flux

1. Prometheus √©value des **rules** (`alerting_rules.yml`).
2. Quand une condition est vraie, une alerte est envoy√©e √† **Alertmanager**.
3. Alertmanager :
    - route l‚Äôalerte,
    - la groupe,
    - peut en inhiber d‚Äôautres,
    - peut la rendre silencieuse.

### 5.2. Routing par labels

Dans `alertmanager.yml` :

```yaml
route:
  receiver: default
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s
  group_interval: 5m
  routes:
    - matchers:
        - env="prod"
        - severity="critical"
      receiver: pagerduty

    - matchers:
        - env="staging"
        - team="backend"
      receiver: slack-backend-staging

receivers:
  - name: default
    email_configs:
      - to: "ops@example.com"

  - name: pagerduty
    pagerduty_configs:
      - routing_key: "<cl√©>"

  - name: slack-backend-staging
    slack_configs:
      - channel: "#staging-backend"
        api_url: "https://hooks.slack.com/services/..."

```

Les **labels** de l‚Äôalerte (`env`, `team`, `severity`, etc.) d√©terminent le **receiver**.

### 5.3. Grouping

`group_by`, `group_wait`, `group_interval` √©vitent le spam :

- `group_by: ['job', 'severity']`
    
    ‚ûú 1 message pour ‚Äú8 instances de l‚ÄôAPI down‚Äù plut√¥t que 8 messages.
    

### 5.4. Inhibition

Ne pas envoyer une alerte ‚ÄúInstanceDown‚Äù si ‚ÄúClusterDown‚Äù est d√©j√† active :

```yaml
inhibit_rules:
  - source_match:
      alertname: "ClusterDown"
    target_match:
      alertname: "InstanceDown"
    equal: ["cluster"]

```

### 5.5. Silences temporaires (`amtool`)

`amtool` (install√© avec Alertmanager) permet de g√©rer les silences en CLI.

Exemple : silence de 2h sur l‚Äôalerte `InstanceDown` du cluster `prod-eu` :

```bash
amtool silence add \
  alertname="InstanceDown" \
  cluster="prod-eu" \
  --duration=2h \
  --comment="Maintenance planifi√©e prod-eu" \
  --author="goose"

```

Listes les silences :

```bash
amtool silence query

```

Supprimer un silence :

```bash
amtool silence expire <ID>

```

üß† **Id√©es d‚Äôusage :**

- Avant un d√©ploiement risqu√© ‚ûú silence sur `env="staging"`.
- Pendant une op√©ration r√©seau ‚ûú silence sur les alertes `InstanceDown` li√©es.

---

## 6. Surveiller de l‚Äôext√©rieur : Blackbox Exporter

### 6.1. Principe

M√™me si tout est vert c√¥t√© Prometheus interne, **tes utilisateurs**, eux, voient :

- un site HTTP,
- un port TCP,
- un certificat TLS,
- une r√©solution DNS.

Le **Blackbox Exporter** simule cette vision ‚Äúc√¥t√© client‚Äù :

- ping ICMP,
- requ√™te HTTP/HTTPS,
- test TCP,
- v√©rification TLS, DNS, etc.

Il expose ensuite des m√©triques que Prometheus scrappe.

### 6.2. Types de sondes

Modules courants (dans `blackbox.yml`) :

- `http_2xx` ‚ûú HTTP OK attendu.
- `tcp_connect` ‚ûú port accessible.
- `icmp` ‚ûú ping.
- `tls` ‚ûú d√©tails du certificat.

### 6.3. Exemple de config Prometheus

```yaml
scrape_configs:
  - job_name: 'blackbox'
    metrics_path: /probe
    params:
      module: [http_2xx]     # module d√©fini dans blackbox.yml
    static_configs:
      - targets:
          - https://example.com
          - https://api.monsite.com/health
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - target_label: instance
        replacement: blackbox
      - target_label: __address__
        replacement: blackbox-exporter:9115

```

Ici, c‚Äôest **Prometheus** qui appelle Blackbox, en lui passant la `target` √† tester.

### 6.4. Id√©es d‚Äôalertes

- HTTP non 2xx / temps de r√©ponse > X secondes.
- Certificat TLS expirant dans moins de 15 jours.
- Nom de domaine qui ne r√©sout plus en DNS.
- Port SSH d‚Äôun bastion devenu inaccessible.

---

## 7. Grafana ‚Äì Dashboards avanc√©s

### 7.1. Multiplication des data-sources

Grafana peut se connecter √† :

- **Prometheus** ‚ûú m√©triques.
- **Loki / ELK** ‚ûú logs.
- **Tempo / Jaeger** ‚ûú traces.
- **CloudWatch, Azure Monitor** ‚ûú m√©triques cloud.
- Bases SQL (PostgreSQL, MySQL‚Ä¶) pour exposer des indicateurs m√©tier.

L‚Äôid√©e : **une seule interface** pour croiser :

- un pic de CPU (Prometheus),
- un message d‚Äôerreur pr√©cis (Loki),
- la trace d√©taill√©e de la requ√™te (Tempo).

Visuel simple des 3 piliers :

```mermaid
mindmap
  root((Observabilit√©))
    M√©triques
      CPU
      RAM
      Requ√™tes/sec
    Logs
      Erreurs
      √âv√©nements m√©tier
    Traces
      Parcours d'une requ√™te
      Microservices

```

### 7.2. Variables dynamiques

Les variables Grafana rendent un dashboard **r√©utilisable** :

- `$env` ‚ûú `dev`, `staging`, `prod`
- `$cluster` ‚ûú `k8s-eu`, `k8s-us`
- `$job` ‚ûú `api`, `ui`, `worker`

Tu d√©finis tes variables dans l‚Äôonglet **Dashboard settings ‚Üí Variables**, par exemple :

- Type : `Query`
- Data source : Prometheus
- Query : `label_values(up, env)`

Tu peux ensuite utiliser `$env` dans :

- tes requ√™tes PromQL :
    
    `rate(http_requests_total{env="$env", job="$job"}[5m])`
    
- les titres de panels,
- les liens de dashboards.

### 7.3. Liaisons entre dashboards

Exemples de navigation utile :

- Dashboard ‚ÄúVue globale‚Äù ‚ûú liste de services.
- En cliquant sur un service, tu vas sur ‚ÄúD√©tail service‚Äù avec `$job` pr√©-rempli.
- Depuis ‚ÄúD√©tail service‚Äù, lien vers :
    - un dashboard ‚ÄúLogs du service‚Äù (Loki),
    - un dashboard ‚ÄúTraces lentes‚Äù (Tempo).

Tu peux cr√©er :

- des **Panel links** (clic sur un graphe),
- des **Dashboard links** (barre en haut),
- des ‚Äúdrill-downs‚Äù qui passent des variables via l‚ÄôURL (`?var-env=prod&var-job=api`).

---

## 8. Synth√®se & checklist

### 8.1. Architecture type ‚ÄúMonitoring avanc√©‚Äù

```mermaid
graph TB
  subgraph Apps
    A1[Services / Exporters] --> PL1[Prometheus Leaf 1]
    A2[Services / Exporters] --> PL2[Prometheus Leaf 2]
  end

  PL1 -->|/federate| PC[Prometheus Central]
  PL2 -->|/federate| PC

  PC --> AM[Alertmanager]
  PC --> RW[(Remote Write -> Thanos / InfluxDB)]

  BBox[Blackbox Exporter] --> PC

  PC --> G[Grafana]
  L[(Loki / ELK)] --> G
  T[(Tempo / Jaeger)] --> G

```

### 8.2. Checklist perso

- [ ]  Mettre en place **au moins 2 Prometheus Leaf + 1 central** pour tester la f√©d√©ration.
- [ ]  Configurer **Remote Write** vers une petite base longue dur√©e (ex : InfluxDB docker).
- [ ]  Instrumenter **une vraie appli** avec des **m√©triques m√©tier**.
- [ ]  Ajouter des **alertes avanc√©es** (routing, grouping, inhibition).
- [ ]  Installer le **Blackbox Exporter** et ajouter :
    - un check HTTP sur ton site,
    - un check TLS sur ton domaine.
- [ ]  Cr√©er **un dashboard Grafana multi-data-sources** (Prometheus + logs).
- [ ]  Utiliser **au moins 2 variables** (`$env`, `$job`) et **un lien** vers un second dashboard.